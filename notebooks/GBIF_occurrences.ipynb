{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBIF - The Global Biodiversity Information Facility\n",
    "\n",
    "This notebook shows how to access biological occurrence data from GBIF, a wonderful resource for biologists and anyone interested in biological data. \n",
    "\n",
    "\n",
    "## API Interface\n",
    "We'll start by making API calls to the Occurrence API, which holds records of where and when a particular organism was observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://api.gbif.org/v1/occurrence/search?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of additional parameters you can add, here's the list, but you can find the descriptions for each parameter at the bottom of this page: https://www.gbif.org/developer/occurrence.\n",
    "\n",
    "__Optional Parameters:__ q, basisOfRecord, catalogNumber, collectionCode, continent, country, datasetKey, decimalLatitude, decimalLongitude, depth, elevation, eventDate, geometry, hasCoordinate, hasGeospatialIssue, institutionCode, issue, lastInterpreted, mediaType, month, occurrenceId, organismId, protocol, license, publishingCountry, publishingOrg, crawlId, recordedBy, recordNumber, scientificName, locality, stateProvince, waterBody, taxonKey, kingdomKey, phylumKey, classKey, orderKey, familyKey, genusKey, subGenusKey, speciesKey, year, establishmentMeans, repatriated, typeStatus, facet, facetMincount, facetMultiselect, facet, paging\n",
    "\n",
    "For this example, I'm going to be using the genusKey (I'll have to use the 'q' parameter first, which is just a general query parameter, to find the appropriate genusKey for my genus of interest), hasCoordinate, and hasGeospatialIssue parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(base_url+'&limit=300'+'&q=Ayenia'+'&hasCoordinate=true'+'&hasGeospatialIssue=false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['offset', 'limit', 'endOfRecords', 'count', 'results', 'facets'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial['endOfRecords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3152178"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the genusKey for Ayenia\n",
    "trial['results'][0]['genusKey']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these few lines of exploratory code, we can now write a script that will download all of the data for this genus. The responses to the query are paginated, meaning we only get 300 records per request. The `'offset'` parameter tells which record is the beginning of the page. The `'endOfRecords'` parameter lets us know if the last record of the query is included in the response. Knowing this, we want to construct a script that will keep downloading new pages until `'endOfRecords' = True`. Each time, we'll concatenate the records that are stored in `'results'` to a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GBIF_response(base_url, offset, params, df):\n",
    "    \"\"\"Performs an API call to the base URL with additional parameters listed in 'params'. Concatenates response to \n",
    "    a Pandas DataFrame, 'df'.\"\"\"\n",
    "    #Construct the query URL\n",
    "    query = base_url+'&'+f'offset={offset}'\n",
    "    for each in params:\n",
    "        query = query+'&'+each\n",
    "    #Call API\n",
    "    response = requests.get(query)\n",
    "    #If call is successful, add data to df\n",
    "    if response.status_code != 200:\n",
    "        print(f\"API call failed at offset {offset} with a status code of {response.status_code}.\")\n",
    "    else:\n",
    "        result = response.json()\n",
    "        df_concat = pd.concat([df, pd.DataFrame.from_dict(result['results'])], axis = 0, ignore_index = True, sort = True)\n",
    "        endOfRecords = result['endOfRecords']\n",
    "        return df_concat, endOfRecords, response.status_code\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['limit=300', 'genusKey=3152178', 'hasCoordinate=true', 'hasGeospatialIssue=false']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "endOfRecords = False\n",
    "offset = 0\n",
    "status = 200\n",
    "\n",
    "while endOfRecords == False and status == 200:\n",
    "    df, endOfRecords, status = get_GBIF_response(base_url, offset, params, df)\n",
    "    offset = len(df) + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Now that we have our DataFrame with all the records in it, I'm going to first save the full DataFrame as a CSV file, then I'll start cleaning up the data. A lot of the cleaning I'm going to do is based on my *very specialized* knowledge of this genus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/Ayenia_full_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (1,5,6,7,9,14,22,23,32,33,37,38,39,41,46,54,56,64,65,66,67,68,69,70,71,72,73,74,75,76,82,83,87,88,98,100,101,102,103,107,108,109,111,112,113,115,116,119,121,122,123,124,127,128,129,130,134,137,139,140,141,142,143,146,152,155,158,159,160,161,163,164,165,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Read back in csv file\n",
    "df = pd.read_csv(\"../data/Ayenia_full_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['key', 'datasetKey', 'publishingOrgKey', 'installationKey', 'publishingCountry', 'protocol', 'lastCrawled', 'lastParsed', 'crawlId', 'extensions', 'basisOfRecord', 'taxonKey', 'kingdomKey', 'phylumKey', 'classKey', 'orderKey', 'familyKey', 'genusKey', 'speciesKey', 'acceptedTaxonKey', 'scientificName', 'acceptedScientificName', 'kingdom', 'phylum', 'order', 'family', 'genus', 'species', 'genericName', 'specificEpithet', 'taxonRank', 'taxonomicStatus', 'decimalLongitude', 'decimalLatitude', 'year', 'month', 'day', 'eventDate', 'issues', 'modified', 'lastInterpreted', 'references', 'license', 'identifiers', 'media', 'facts', 'relations', 'geodeticDatum', 'class', 'countryCode', 'recordedByIDs', 'identifiedByIDs', 'country', 'identifier', 'recordedBy', 'created', 'locality', 'gbifID', 'occurrenceID', 'associatedSequences', 'taxonID', 'higherClassification'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial['results'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the records that aren't real species or missing a species-level identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleanedspecies = df.drop(index = df[(df['species'] == 'Ayenia villicocca') \n",
    "                                       | (df['species'] == 'Ayenia echinococca') \n",
    "                                       | (df['species'].isna())\n",
    "                                       | (df['specificEpithet'] == 'villicocca')\n",
    "                                       | (df['specificEpithet'] == 'echinococca')\n",
    "                                       | (df['specificEpithet'].isna())\n",
    "                                       | (df['scientificName'] == 'Ayenia L.')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleanedspecies.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I want to drop the records that aren't based on a real specimen that is preserved in a museum. GBIF includes observations from iNaturalist, another really cool biological data source based on people uploading pictures of organisms they see. However, observations on iNaturalist may not be checked by specialists in the field, therefore the identification of the species may not be right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleanedobservations = df_cleanedspecies.drop(index = df_cleanedspecies[df_cleanedspecies['basisOfRecord'] != 'PRESERVED_SPECIMEN'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleanedobservations.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's just keep a few of the columns that we'll need for making a biodiversity heatmap. There's a lot of extra stuff in here that we just don't need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleanedobservations[['species', 'decimalLongitude', 'decimalLatitude', 'country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>decimalLongitude</th>\n",
       "      <th>decimalLatitude</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ayenia tomentosa</td>\n",
       "      <td>-40.700556</td>\n",
       "      <td>-19.530000</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ayenia tomentosa</td>\n",
       "      <td>-40.700556</td>\n",
       "      <td>-19.530000</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ayenia tomentosa</td>\n",
       "      <td>-38.646389</td>\n",
       "      <td>-8.592222</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ayenia tomentosa</td>\n",
       "      <td>-38.023611</td>\n",
       "      <td>-8.105278</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ayenia tomentosa</td>\n",
       "      <td>-38.113056</td>\n",
       "      <td>-8.592222</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            species  decimalLongitude  decimalLatitude country\n",
       "0  Ayenia tomentosa        -40.700556       -19.530000  Brazil\n",
       "1  Ayenia tomentosa        -40.700556       -19.530000  Brazil\n",
       "2  Ayenia tomentosa        -38.646389        -8.592222  Brazil\n",
       "3  Ayenia tomentosa        -38.023611        -8.105278  Brazil\n",
       "4  Ayenia tomentosa        -38.113056        -8.592222  Brazil"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv(\"../data/Ayenia_cleaned_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our cleaned data, we can try mapping it next! We'll move to a new notebook for that. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
